%!TEX root = ../../thesis.tex
\chapter{Kompaktierung}
\label{cha:compacting}
Mit dem Mark-Sweep-Algorithmus und der Referenzzählung sind in den vorigen Kapiteln zwei grundlegende Ansätze eingeführt worden, die eine Wiederverwendung bereits genutzten Speichers durch Freigabe nicht mehr benötigter Objekte realisieren.
Außen vor gelassen wurde bislang jedoch ein Phänomen, das mit zunehmender Laufzeit eines Programms in Erscheinung tritt:
die \textbf{Fragmentierung} des Heaps.
Je häufiger eine Garbage Collection zum Einsatz kommt, umso wahrscheinlicher ist es, dass die erreichbaren Objekte keinen zusammenhängenden Speicherbereich mehr bilden.
In der Folge ist auch der freie Speicher in mehrere unzusammenhängende Teile unterschiedlicher Größe aufgeteilt.
Dies kann sich nachteilig auf die Performance einer Anwendung auswirken:
Bildet der freie Speicher einen möglichst großen zusammenhängenden Bereich, so können viele aufeinanderfolgende Speicheranforderungen in hoher Geschwindigkeit erfüllt werden.
Andernfalls benötigen Speicherallokationen mehr Zeit, da eine hinreichend große \textit{Lücke} gefunden werden muss, die die angeforderte Speichermenge aufnehmen kann.
Im schlimmsten Fall schlägt die Allokation fehl, da keine geeignete Lücke gefunden werden kann, obwohl in der Summe genügend freier Speicher vorhanden wäre.
Dies wiederum führt zu weiteren Auslösungen der Garbage Collection, was die Performance weiter beeinträchtigt.
Zudem benötigt eine Anwendung mit stark fragmentiertem Heap einen größeren Teil des gesamten Arbeitsspeichers.
Eine Kompaktierung lebendiger Objekte kann ferner die räumliche Lokalität verbessern.

\begin{figure}[h]
	\centering
	\includestandalone[scale=1.2]{img/tikz/ch4-fragmentation}
	\caption[Fragmentierter Heap]{Ein stark fragmentierter Heap erschwert die Allokation größerer Speichermengen, auch wenn ein Großteil des Heaps ungenutzt ist.}
	\label{fig:fragmentation}
\end{figure}

Die Vermeidung von Heapfragmentierung durch optimale Allokation ist nicht zielführend, da die Prognose zukünftiger Allokationen in der Regel unmöglich und das Finden einer entsprechenden Allokationsstrategie NP-schwer ist (vgl. \cite{robson1980}).
Allerdings existieren akzeptable Lösungen, die die Fragmentierung des Heaps durch geschickte Allokation zumindest in Grenzen halten.\footnote{Für einen Überblick siehe etwa \cite[Kap. 7]{handbook}.}
Nichtsdestoweniger werden in diesem Kapitel ausschließlich Algorithmen betrachtet, die den Heap im Rahmen einer Garbage Collection \textbf{kompaktieren}, da die Durchführung eines Kollektionszyklus ursächlich für die Entstehung von Fragmentierung ist.

Algorithmen, die im Rahmen der Garbge Collection die Fragmentierung des Heaps beseitigen oder verhindern, lassen sich grob in zwei Kategorien einteilen:
Die erste Kategorie der \textbf{Mark-Compact-Algorithmen} baut auf der Markierungsphase eines Mark-Sweep-Kollektors auf und können die Bereinigungsphase ersetzen, indem aus den Markierungsinformationen die zukünftigen Positionen der Objekte generiert werden.
Im Folgenden werden mit dem \textit{LISP-2-Algorithmus} und \textit{The Compressor} zwei Exemplare dieser Gattung vorgestellt.
Die zweite Kategorie der \textbf{kopierenden} Algorithmen -- gelegentlich auch \textit{Mark-Copy-Algorithmen} genannt -- vereinen Markierungs- und Kompaktierungsphase, indem als erreichbar identifizierte Objekte unmittelbar an eine neue Position kopiert werden.
Hier wird exemplarisch ein Algorithmus betrachtet, der den Heap in zwei Halbräume aufteilt.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
 % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 


\section{LISP-2-Kompaktierung}
\label{sec:lisp2-compact}
Zunächst wird ein Algorithmus behandelt, der auf dem Mark-Sweep-Ansatz aufbaut und in seiner ursprünglichen Form für \textit{LISP 2}\footnote{LISP 2 war als Nachfolger von LISP gedacht und sollte einige Einschränkungen beheben, die bereits von \textsc{McCarthy} aufgeführt wurden. Aus Kostengründen wurde die Entwicklung von LISP 2 letztlich eingestellt (vgl. \cite{lisp-history}).} konzipiert wurde, weswegen er in der Literatur häufig als \textbf{LISP-2-Algorithmus} bezeichnet wird (vgl. \cite[Kap. 3.2]{handbook} und \cite{lisp2gc}).
Die grundlegende Idee ist, die Bereinigungsphase nach der Markierung erreichbarer Objekte durch eine Kompaktierungsphase zu ersetzen, die alle markierten Objekte an den Beginn des Heaps verschiebt.
Dabei werden verwaiste Objekte entweder überschrieben oder befinden sich anschließend außerhalb des kompaktierten Bereichs, sodass sie durch zukünftige Allokationen überschrieben werden können.

Wie schon in Kapitel~\ref{cha:mark-sweep} wird vorausgesetzt, dass eine Prozedur zu Verfügung steht, die die Adrese des nachfolgenden Objekts liefert, sofern existent.
Entsprechend kann leicht eine Prozedur \Method{nextMarkedObject} realisiert werden, die nur markierte Objekte liefert.
Weiter soll eine Prozedur \Method{moveObject}(\Var{old}, \Var{new}) existieren, die das Objekt an der Speicheradresse \Var{old} an die Speicheradresse \Var{new} verschiebt.

Der Algorithmus verfährt nun recht intuitiv (siehe Abbildung~\ref{fig:lisp2}):
Beginnend am Anfang des Heaps werden der Reihe nach alle markierten Objekte besucht und an die vorderste Stelle bewegt, an der noch kein markiertes Objekt steht.
Dabei wird für jedes verschobene Objekt alte und neue Speicheradresse in einer Tabelle \Var{log} hinterlegt (Zeile~6 in Algorithmus~\ref{algo:lisp2gc}).
Nach jeder Verschiebung wird der Zeiger \Var{pos} auf das neue Ende des kompaktierten Bereichs und \Var{next} auf das nächste markierte Objekt gesetzt (Zeile~8f).
Die erreichbaren Objekte befinden sich nun lückenlos am Anfang des Heaps.

\newpage

\begin{figure}[H]
	\centering
	\includestandalone[scale=1]{img/tikz/ch4-lisp2}
	\caption[LISP-2-Algorithmus]{Veranschaulichung des LISP-2-Algorithmus.}
	\label{fig:lisp2}
\end{figure}

\vfill

\begin{algorithm}[h!]
\begin{algorithmic}[1]
	\State \Atomic \MethodHead{compact}():
	\State \quad $\Var{pos} \gets \Var{HEAP\_START}$	\Comment{Zeiger auf Ende des kompaktierten Bereichs}
	\State \quad $\Var{next} \gets \Method{nextMarkedObject}(\Var{HEAP\_START})$ \Comment{Zeiger auf nächstes Objekt}
	\State \quad \WHILE $\Var{next} \neq \Null$			
	\State \quad \quad \IF $\Var{pos} \neq \Var{next}$	\Comment{Tue nichts, wenn noch im defragmentierten Bereich}
	\State \quad \quad \quad \Method{addLog}(\Var{next}, \Var{pos})		\Comment{Notiere alte und neue Adresse}
	\State \quad \quad \quad \Method{moveObject}(\Var{next}, \Var{pos})	\Comment{Verschiebe Objekt im Speicher}
	\State \quad \quad $\Var{pos} \gets \Var{pos} + \Method{sizeOf}(\Var{*pos})$	\Comment{Zeiger weitersetzen}
	\State \quad \quad $\Var{next} \gets \Method{nextMarkedObject}(\Var{next})$
	\State \quad \Method{updateRefs}()
	\Statex
	\State \MethodHead{updateRefs}():
	\State \quad \FOREACH $\Var{field} \in \Fields(\Roots)$
	\State \quad \quad \IF $\Var{*field} \in \Var{log}$ \Comment{Felder von Basisobjekten anpassen}
	\State \quad \quad \quad $\Var{*field} \gets \Var{log}(\Var{*field})$
	\State \quad $\Var{pos} \gets \Method{nextMarkedObject}(\Var{HEAP\_START})$		\Comment{Felder von Heapobjekten anpassen}
	\State \quad \WHILE $\Var{pos} \neq \Null$
	\State \quad \quad \FOREACH $\Var{field} \in \Fields(\Var{*pos})$
	\State \quad \quad \quad \IF $\Var{*field} \in \Var{log}$
	\State \quad \quad \quad \quad $\Var{*field} \gets \Var{log}(\Var{*field})$
	\State \quad \quad $\Var{pos} \gets \Method{nextMarkedObject}(\Var{pos})$
	\State \quad \Method{clear}(\Var{log})		\Comment{Tabelle aufräumen}
\end{algorithmic}
\caption[LISP-2-Kompaktierung]{LISP-2-Kompaktierung (vgl. \cite[S. 35]{handbook} und \cite[S. 7ff]{lisp2gc}).}
\label{algo:lisp2gc}
\end{algorithm}

\newpage

Im Anschluss müssen alle Referenzen auf verschobene Objekte in den Feldern aller Objekte aktualisiert werden.
Die Prozedur \Method{updateRefs} iteriert dabei zunächst über alle Felder von Basisobjekten (Zeile~12 bis 14).
Falls der Inhalt \Var{*field} eines Felds als Schlüssel in der Tabelle auftaucht, so handelt es sich um die alte Adresse eines verschobenen Objekts.
Entsprechend muss der Feldinhalt auf die neue Adresse \Var{log}(\Var{*field}) gesetzt werden.
Um auch die Objekte des Heaps anzupassen, wird dieser ein weiteres Mal linear traversiert und analog die Felder aller markierten Objekte angepasst (Zeile~15 bis 20).
Zuletzt wird die Tabelle mit den zwischengespeicherten Adressen geleert.
Dadurch, dass der Heap in aufsteigender Reihenfolge durchlaufen wird, die Objekte jedoch in entgegengesetzte Richtung verschoben werden, werden keine lebendigen Daten überschrieben und der Algorithmus arbeitet korrekt.

Die Laufzeit des gesamten Algorithmus lässt sich wie folgt einschätzen:
Im schlimmsten Fall läuft der Zeiger \Var{pos} in der Prozedur \Method{compact} über den gesamten Heap.
Davon ausgehend, dass das Hinzufügen eines Adresspaares zur Tabelle \Var{log} in $\oh(1)$ möglich ist  (siehe auch Abschnitt~\ref{sec:rc-optimizing}), ergibt sich dadurch eine Komplexität von $\oh(\abs{\mathbb{H}})$ für die Verschiebung der erreichbaren Objekte an den Anfang des Heaps.
Für die Aktualisierung der Referenzen ergibt sich die Laufzeit aus der Anzahl der Felder der Basisobjekte sowie einer weiteren Traversierung über den Heap.
Somit können folgende Abschätzungen festgehalten werden:

\begin{mybox}
\begin{satz}[Komplexität des LISP-2-Algorithmus]
	Für den LISP-2-Algorithmus gelten folgende Eigenschaften:
	\begin{enumerate}[(1)]
		\item Die Laufzeit der Verschiebungsphase ist $\oh(|\HeapSize|)$.
		\item Die Laufzeit von \Method{updateRefs} ist $\oh\enb{\sum\limits_{\Var{a} \in \Roots}^{} \abs{\Fields(a)} + \abs{\HeapSize}}$.
	\end{enumerate}
\end{satz}
\end{mybox}

Der Speicherplatzbedarf, der zusätzlich durch die Kompaktierung anfällt, ist im Wesentlichen durch die Realisierung der Tabelle \Var{log} bestimmt.
Alternativ -- und näher am ursprünglichen Algorithmus -- kann zur Speicherung der neuen Adresse eines Objekts auch ein zusätzliches Feld im Header jedes Objekts eingerichtet werden.
In diesem Fall ist allerdings ein weiterer Durchlauf über den Heap notwendig, da die Referenzen in den Feldern aller Objekte anpasst werden müssen, bevor die Objekte an ihre neue Position verschoben werden können (vgl. \cite[S. 16]{morikawa2013}).

Ein wesentlicher Nachteil des Algorithmus ist, dass er selbst bei geringer Fragmentierung des Heaps viele Speicheroperationen bedarf.
So werden etwa auch dann fast alle Objekte verschoben, wenn nur ein kleiner Bereich zu Beginn des Heaps fragmentiert ist.
Im Falle von großen Heaps mit vielen Objekten ist die Ausbeute der Kompaktierung gering, der Aufwand zur Aktualisierung von Speicheradressen allerdings sehr hoch.
Insofern sollte abgewägt werden, ob die Ausführung bei jedem Garbage-Collection-Zyklus zielführend ist.
\textsc{Printezis} präsentiert beispielsweise ein heuristisches Kriterium und seine Umsetzung für Java, um zur Laufzeit zu entscheiden, ob eine Kompaktierung des Heaps erfolgen sollte.
Wenn der Heap vergrößert wird oder aufeinanderfolgende Speicherallokationen nicht mehr schnell genug erfüllt werden können, ist eine Kompaktierung sinnvoll, andernfalls genügt der Mark-Sweep-Algorithmus (vgl. \cite[Kap. 3.4]{printezis2001}).
Andere Algorithmen vermeiden diese Problematik, indem sie den Heap von beiden Seiten traversieren und hinten stehende Objekte in freie Speicherbereiche im vorderen Teil des Heaps verschieben (vgl. \cite[S. 32f]{handbook}).
Dieses Vorgehen hat jedoch den entscheidenden Nachteil, dass die Reihenfolge der Objekte im Heap zerstört wird.
Damit wird die Arbeit von Allokatoren, die verwandte Objekte zur Optimierung der räumlichen Lokalität möglichst benachbart anlegen, zunichte gemacht.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
 % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 


\section{Compressor-Algorithmus}
\label{sec:compressor}

Der von \textsc{Kermany} und \textsc{Petrank} vorgestellte \textbf{Compressor-Algorithmus} zielt darauf ab, die durch die Kompaktierung entstehenden Verzögerungen vor allem für größere Heaps zu minimieren, indem in einem einzigen Durchlauf Objekte an ihre neue Speicheradresse verschoben werden und sämtliche Referenzen angepasst werden \cite{kermany2006}.
Dazu wird davon ausgegangen, dass der Heapspeicher in gleich große Blöcke eingeteilt ist und Objekte an \textit{Wörtern} ausgerichtet angelegt werden.\footnote{\textsc{Kermany} und \textsc{Petrank} gehen exemplarisch von einer Wortbreite von 4 Bytes (32 Bit) und einer Blockgröße von 512 Bytes aus.}
Während der Markierungsphase kann dann ein Bitvektor erzeugt werden, der angibt, ob ein Wort durch ein erreichbares Objekt belegt ist (siehe Abbildung~\ref{fig:bitvector}).
Alle weiteren Berechnungen können dann mithilfe des Bitvektors realisiert werden, anstelle auf den Heap zuzugreifen.

\begin{figure}[h]
	\centering
	\includestandalone[scale=1.1]{img/tikz/ch4-bitvector}
	\caption[Bitvektor]{Ein Bitvektor speichert zu jedem Wort des Heaps, ob es durch ein erreichbares Objekt belegt wird.}
	\label{fig:bitvector}
\end{figure}

Zu Beginn der Kompaktierungsphase wird durch die Prozedur \Method{calculateOffsets} in Algorithmus~\ref{algo:compressor} ein Vektor \Var{offset} angelegt, der für jeden Block $\Var{blk}_k$ angibt, an welche Speicheradresse das erste Objekt des Blocks verschoben werden muss.
Diese ergibt sich aus dem Offset des vorigen Blocks $\Var{blk}_{k-1}$ und dem Speicherplatz, den die Objekte belegen, deren Beginn im Block $\Var{blk}_{k-1}$ liegt.
Diese Information kann durch Zählung der korrespondierenden Bits im Bitvektor erhalten werden.
Die neue Speicheradresse eines Objekts kann nun wie folgt anhand der alten Speicheradresse \Var{adr} ermittelt werden (vgl. Prozedur \Method{newAddress}):
Zunächst wird anhand des Blocks, in dem sich die Speicheradresse befindet, der Offset bestimmt.
Die genaue Zieladresse ergibt sich nun durch den Speicherplatz der Objekte, deren Beginn im gleichen Block liegt, sich aber vor \Var{adr} befinden (Zeile 8f).
Dies kann ebenfalls durch Zählung der belegten Bits erfasst werden.
Somit ist sichergestellt, dass die Reihenfolge der Objekte im Heap erhalten bleibt und keine erreichbaren Objekte zerstört werden.

\begin{algorithm}[h]
\begin{algorithmic}[1]
	\State \MethodHead{calculateOffsets}():
	\State \quad $\Var{offset}(0) \gets \Var{HEAP\_START}$
	\State \quad \FOR $\Var{k} \in \{1, \dots, \abs{\Blocks}\}$
	\State \quad \quad $\Var{offset}(k) \gets \Var{offset}(k-1) + \Method{usedWords}(i-1)$
	\Statex
	\State \MethodHead{newAddress}(\Var{adr}):
	\State \quad $\Var{result} \gets \Var{offset}(\Var{block}(\Var{adr}))$	\Comment{Ermittle Offset des zugehörigen Blocks}
	\State \quad \FOREACH $\Var{obj} \in \Var{block}(\Var{adr})$
	\State \quad \quad \IF $\Var{\&obj} < \Var{adr}$	\Comment{Addiere Anzahl Wörter, die vor \Var{adr} belegt sind}
	\State \quad \quad \quad $\Var{result} \gets \Var{result} + \Method{sizeOf}(\Var{obj})$
	\State \quad \Return \Var{result}
	\Statex
	\State \MethodHead{compactAndUpdate}():
	\State \quad \FOREACH $\Var{field} \in \Fields(\Roots)$
	\State \quad \quad $\Var{*field} \gets \Method{newAddress}(\Var{*field})$
	\State \quad $\Var{pos} \gets \Method{nextMarkedObject}(\Var{HEAP\_START})$
	\State \quad \WHILE $\Var{pos} \neq \Null$	\Comment{Passe Objektfelder an}
	\State \quad \quad \FOREACH $\Var{field} \in \Fields(\Var{*pos})$
	\State \quad \quad \quad $\Var{*field} \gets \Method{newAddress}(\Var{*field})$
	\State \quad \quad \Method{moveObject}(\Var{pos}, \Method{newAddress}(\Var{pos}))
	\State \quad \quad $\Var{pos} \gets \Method{nextMarkedObject}(\Var{pos})$
\end{algorithmic}
\caption[Compressor-Algorithmus]{Der Compressor-Algorithmus nach \textsc{Kermany} und \textsc{Petrank} (\cite{kermany2006}).}
\label{algo:compressor}
\end{algorithm}

Betrachten wir beispielhaft, wie die neuen Speicheradressen der Objekte \Var{a} bis \Var{d} aus Abbildung~\ref{fig:bitvector} bestimmt werden, nachdem der Offsetvektor erstellt wurde (Abbildung~\ref{fig:compressor-example}).
Für Objekt \Var{a} wird zunächst der Offset $0$ nachgeschlagen, da sich \Var{a} im ersten Block befindet.
Da \Var{a} das erste Element des Blocks ist, ist dieser Offset auch die neue Speicheradresse von \Var{a}.
Für \Var{b} wird ebenfalls Offset $0$ ermittelt, allerdings wird dieser um $4$ korrigiert, da sich \Var{a} vor \Var{b} befindet und vier Wörter belegt.
Analog zu \Var{a} wird für \Var{c} die neue Speicheradresse $8$ ermittelt, da \Var{c} das einzige Element im zweiten Block ist.
Für \Var{d} ergibt sich als Offset und Speicheradresse der Wert $15$:
Zwar befindet sich auch der hintere Teil von \Var{c} im dritten Block, allerdings wurde die Größe von \Var{c} bereits bei der Offsetberechnung berücksichtigt, sodass der Offset hier nicht korrigiert werden muss.

%\newpage

\begin{figure}[h]
	\centering
	\includestandalone[scale=1.1]{img/tikz/ch4-compressor-example}
	\caption[Beispiel zum Compressor-Algorithmus]{Beispiel zum Compressor-Algorithmus. Die neue Speicheradresse eines Objekts berechnet sich aus dem Offset des zugehörigen Blocks und dem Speicherplatz, der durch die davorliegenden Objekte im Block beansprucht wird.}
	\label{fig:compressor-example}
\end{figure}

Der Performancegewinn durch den Verzicht auf eine zweite Heaptraversierung ist offenkundig, wird jedoch mit zusätzlichem Speicherbedarf erkauft.
Der Bitvektor benötigt ein Bit pro Wort Speicherplatz, während der Offsetvektor pro Block ein Wort belegt.
Für die oben genannte Wortbreite und Blockgröße ergibt sich daher ein Overhead von etwa 4\% des Heaps.
Eine Erhöhung der Wortbreite $w$, an der Objekte im Heap ausgerichtet werden, kann diesen Anteil zwar reduzieren (siehe Tabelle~\ref{tab:compressor}), aber auch eine ineffizientere Speichernutzung verursachen, da jedes Objekt stets ein Vielfaches von $w$ an Speicher belegt.
Größere Blöcke wiederum erhöhen den Aufwand zur Berechnung der neuen Speicheradressen, da eine höhere Anzahl an Objekten pro Block zu erwarten ist.

\begin{figure}[h]
	\centering \renewcommand{\arraystretch}{1.15} \setstretch{1.15}
	\begin{tabular}{|r|cccc|}
		\hline
		$b \downarrow \diagdown w \rightarrow$ &  \textbf{16}   &  \textbf{32}   &  \textbf{64}   &  \textbf{128}  \\ \hline
                             & \hspace{1.5cm}  &  \hspace{1.5cm}  &  \hspace{1.5cm}   &   \hspace{1.5cm}   \\[-0.6cm]
		                                 \textbf{256} & 7.0\% & 4.7\% & 4.7\% & 7.0\% \\ \hline
		                                 \textbf{512} & 6.6\% & 3.9\% & 3.1\% & 3.9\% \\ \hline
		                                \textbf{1024} & 6.4\% & 3.5\% & 2.3\% & 2.3\% \\ \hline
		                                \textbf{2048} & 6.3\% & 3.2\% & 2.0\% & 1.6\% \\ \hline
		                                \textbf{4096} & 6.3\% & 3.2\% & 1.8\% & 1.2\% \\ \hline
	\end{tabular} 

	\vspace*{0.3cm}
	
	\caption[Speicherbedarf des Compressor-Algorithmus]{Verhältnis $M$ des Speicherbedarfs des Compressor-Algorithmus zum gesamten Heap in Abhängigkeit von Wortbreite $w$ in Bit und Blockgröße $b$ in Byte. Es gilt $M = \frac{1}{w} + \frac{w}{8 \cdot b}$.}
	\label{tab:compressor}
\end{figure}

Die Korrektheit der beiden vorgestellten Mark-Compact-Algorithmen ergibt sich aus der Korrektheit der Markierungsphase.
Wurden alle erreichbaren Objekte erfasst, werden auch die Zeiger \Var{pos} und \Var{next} im LISP-2-Algorithmus korrekt weitergeschoben, ohne dass es zur Überschreibung erreichbarer Objekte kommt.
Mit gleichem Argument sind auch die berechneten Speicheradressen im Compressor-Algorithmus korrekt.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
 % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 


\section{Kopierende Garbage Collection}
\label{sec:copying}
Die zweite Kategorie der Algorithmen, die eine Kompaktierung des Heaps erreichen, bilden die \textbf{kopierenden} Algorithmen.
Hier werden Markierungs- und Kompaktierungsphase vereint:
Analog zu Mark-Sweep-Ansätzen werden Referenzen verfolgt, um erreichbare Objekte zu identifizieren.
Im Gegensatz zu den in den vorigen beiden Abschnitten vorgestellten Mark-Compact-Algorithmen werden Objekte jedoch nicht durch eine zusätzliche lineare Traversierung des Heaps zusammengefasst, sondern unmittelbar bei Entdeckung an eine neue Position kopiert.
Dazu wird der Heap in zwei Halbräume (engl. \textit{semispaces}) aufgeteilt, zwischen denen die Objekte hin- und herkopiert werden und die nach jedem Kollektionszyklus ihre Rollen tauschen.
Diese Idee wurde ursprünglich von \textsc{Fenichel} und \textsc{Yochelson} für LISP entwickelt (vgl. \cite{fenichel1969}); im Folgenden wird eine Anlehnung an eine Variante von \textsc{Cheney} betrachtet, die ohne Rekursion auskommt (vgl. \cite{cheney1970}).

\begin{algorithm}[h]
\begin{algorithmic}[1]
	\State \MethodHead{initialize}():
%	\State \quad $\Var{spaceSize} \gets (\Var{HEAP\_END} - \Var{HEAP\_START}) / 2$
%	\State \quad $\Var{limit} \gets \Var{HEAP\_START} + \Var{spaceSize}$
	\State \quad $\Var{target} \gets \Var{HEAP\_START}$		\Comment{Erste Hälfte}
	\State \quad $\Var{source} \gets (\Var{HEAP\_START} + \Var{HEAP\_END}) / 2$		\Comment{Zweite Hälfte}
	\State \quad $\Var{pos} \gets \Var{target}$		\Comment{Füllstand}
	\Statex
	\State \Atomic \MethodHead{collect}():
	\State \quad \Method{swap}(\Var{target}, \Var{source})		\Comment{Halbräume tauschen}
%	\State \quad $\Var{limit} \gets \Var{target} + \Var{spaceSize}$
	\State \quad $\Var{pos} \gets \Var{target}$
	\State \quad \FOREACH $\Var{field} \in \Fields(\Roots)$		\Comment{Beginne mit Basisobjekten}
	\State \quad \quad \Method{update}(\Var{field})		\Comment{Feld aktualisieren und Ziel zu \Var{toDo} hinzufügen}
	\State \quad \WHILE $\Var{toDo} \neq \emptyset$		\Comment{Solange kopierte, nicht aktualisierte}
	\State \quad \quad $\Var{ref} \gets \Method{remove}(\Var{toDo})$	\CommentCont{Objekte existieren\dots}
	\State \quad \quad \FOREACH $\Var{field} \in \Fields(\Var{*ref})$
	\State \quad \quad \quad \Method{update}(\Var{field})	\Comment{\dots aktualisiere ihre Felder}
	\State \quad \Method{clear}(\Var{newAdr})
	\Statex
	\State \MethodHead{update}(\Var{field}):
	\State \quad $\Var{oldAdr} \gets \Var{*field}$		\Comment{Adresse aus Feld holen}
	\State \quad \IF $\Var{newAdr}(\Var{oldAdr}) = \Null$	\Comment{Falls Ziel noch nicht kopiert wurde\dots}
	\State \quad \quad $\Var{newAdr}(\Var{oldAdr}) \gets \Var{pos}$		\Comment{\dots definiere neue Position}
	\State \quad \quad $\Method{moveObject}(\Var{oldAdr}, \Var{newAdr}(\Var{oldAdr}))$
	\State \quad \quad $\Var{pos} \gets \Var{pos} + \Method{sizeOf}(\Var{*oldAdr})$	\Comment{Kopiere Objekt an neue Position}
	\State \quad \quad $\Method{add}(\Var{toDo}, \Var{newAdr}(\Var{oldAdr}))$	\Comment{Füge Kopie zu \Var{toDo} hinzu}
	\State \quad $\Var{*field} \gets \Var{newAdr}(\Var{oldAdr})$	\Comment{Feld aktualisieren}
\end{algorithmic}
\caption[Kopierende Garbage Collection nach \textsc{Fenichel}, \textsc{Yochelson}, \textsc{Cheney}]{Kopierende Garbage Collection zwischen Halbräumen nach \textsc{Fenichel}, \textsc{Yochelson} und \textsc{Cheney} (vgl. \cite{fenichel1969} und \cite{cheney1970}).}
\label{algo:copying-gc}
\end{algorithm}

Zur Vorbereitung wird der Heap zu Programmbeginn in zwei Hälften eingeteilt, die durch zwei Zeiger \Var{source} und \Var{target} markiert werden (Prozedur \Method{initialize} in Algorithmus~\ref{algo:copying-gc}).
Der durch \Var{target} referenzierte Halbraum ist stets derjenige, der neu angelegte bzw. zu kopierende Objekte aufnimmt.
Ein dritter Pointer \Var{pos} zeigt den Füllstand von \Var{target} und damit die Position an, an der ein neues Objekt angelegt bzw. kopiert wird.
Der Allokator ist entsprechend so zu modifizieren, dass neue Objekte an der Stelle \Var{pos} angelegt werden und \Var{pos} anschließend angepasst wird, sowie die Garbage Collection bereits dann ausgelöst wird, wenn der freie Speicher in \Var{target} zu Neige geht.

Kommt es zu einem Kollektionszyklus, werden zunächst die Rollen von \Var{source} und \Var{target} vertauscht (Zeile 6).
Der Füllstandsanzeiger \Var{pos} wird auf den Beginn des nun leeren Halbraums \Var{target} gesetzt.
Um alle erreichbaren Objekte aus \Var{source} nach \Var{target} zu kopieren, werden erst alle Felder von Basisobjekten auf Referenzen zu Heapobjekten untersucht (Zeile~8f).
Diese Felder und die entsprechend referenzierten Objekte werden durch die Prozedur \Method{update} bearbeitet.
Diese schlägt in einer Tabelle \Var{newAdr} nach, ob das Objekt bereits nach \Var{target} kopiert und in ihr eine neue Speicheradresse hinterlegt wurde (Zeile~17).
Falls nein, wird die neue Adresse des Objekts auf die Position von \Var{pos} gesetzt, das Objekt an diese Stelle kopiert und \Var{pos} hinter das Objekt gesetzt (Zeile~18 bis~20).
Damit alle Objekte erfasst werden können, die vom kopierten Objekt referenziert werden, wird dieses zu \Var{toDo} hinzugefügt.
In \Var{toDo} befinden sich demnach alle Objekte, die bereits kopiert, aber deren ausgehende Referenzen noch nicht untersucht wurden.
Schließlich kann die Referenz im untersuchten Feld auf die neue Speicheradresse aktualisiert werden (Zeile~22).
Ist in \Var{newAdr} bereits eine Speicheradresse hinterlegt worden, so wurde das Ziel bereits nach \Var{target} kopiert; in diesem Fall genügt es, den Feldinhalt zu aktualisieren.
Die Prozedur \Method{collect} kann anschließend mit der Abarbeitung der Objekte in \Var{toDo} beginnen (Zeile~10 bis~13).

Abbildung~\ref{fig:fenichel-example} veranschaulicht die Arbeitsweise des Algorithmus an einem Beispiel:
Nachdem die Rollen der Halbräume \Var{source} und \Var{target} vertauscht wurden, wird zunächst das einzige Basisobjekt \Var{b} kopiert \textbf{(2)}.
Anschließend wird es zu \Var{toDo} hinzugefügt, was durch eine Nummerierung der Kopie \Var{b'} angezeigt wird \textbf{(3)}.
Da nun alle Basisobjekte kopiert wurden, wird \Var{toDo} abgearbeitet.
Daher werden alle Felder von \Var{b'} untersucht, die Ziele der enthaltenen Referenzen -- hier \Var{f} und \Var{g} -- nach \Var{target} kopiert und die Kopien zu \Var{toDo} hinzugefügt \textbf{(4)}.
Analog wird mit \Var{f'} verfahren \textbf{(5)}.
Bei der Abarbeitung von \Var{g'} tritt nun die Besonderheit auf, dass das referenzierte Objekt \Var{f} bereits kopiert wurde.
Entsprechend wird hier lediglich die Referenz angepasst \textbf{(6)}.
Sobald \Var{toDo} vollständig abgearbeitet wurde, sind alle erreichbaren Objekte kopiert worden und der Halbraum \Var{source} kann in Gänze verworfen werden \textbf{(7)}.

\newpage

\begin{figure}[h!]
	\centering
	\includestandalone[scale=0.9]{img/tikz/ch4-fenichel01}\\[0.5cm]
	\includestandalone[scale=0.9]{img/tikz/ch4-fenichel02}\\[0.5cm]
	\includestandalone[scale=0.9]{img/tikz/ch4-fenichel03}\\[0.5cm]
	\includestandalone[scale=0.9]{img/tikz/ch4-fenichel04}\\[0.5cm]
	\includestandalone[scale=0.9]{img/tikz/ch4-fenichel05}\\[0.5cm]
	\includestandalone[scale=0.9]{img/tikz/ch4-fenichel06}\\[0.5cm]
	\includestandalone[scale=0.9]{img/tikz/ch4-fenichel07}
	\caption[Ausführung der kopierenden Garbage Collection]{Beispielhafte Ausführung von Algorithmus~\ref{algo:copying-gc}. Die Nummerierung der Kopien zeigt ihre aktuelle Position in \Var{toDo} an. Referenzen der ursprünglichen Objekte aus \Var{source} werden hier aus Gründen der Übersichtlichkeit nicht mehr aufgeführt, sobald das Objekt nach \Var{target} kopiert wurde.}
	\label{fig:fenichel-example}
\end{figure}

Die kopierten Objekte, die sich in \Var{toDo} befinden, sind vergleichbar mit den grauen Objekten der Drei-Farben-Abstraktion (siehe Abschnitt~\ref{sec:tricolor}):
Sie wurden bereits durch den Kollektor entdeckt und nach \Var{target} kopiert, aber ihre Felder wurden noch nicht auf Referenzen zu noch unentdeckten Objekten untersucht.
Entsprechend analog zu Satz~\ref{satz:tricolor-correctness} lässt sich die Terminierung des Algorithmus beweisen, da kein Objekt mehrfach zu \Var{toDo} hinzugefügt wird.

\newpage

\begin{mybox}
\begin{satz}[Korrektheit der kopierenden Garbage Collection]
	Die kopierende Garbage Collection nach \textsc{Fenichel}, \textsc{Yochelson} und \textsc{Cheney} ist korrekt.
\end{satz}
\end{mybox}

\begin{proof}
	Wir beweisen, dass nach Terminierung des Algorithmus kein erreichbares Objekt im Halbraum \Var{source} verbleibt.
	Sei also $\Var{a} \in \Reach$ ein erreichbares Objekt.
	Dann gilt $\Var{b[i]} = \Var{\&a}$ für Feld \Var{b[i]} eines Objektes \Var{b}.
	Ist $\Var{b} \in \Roots$, so ist $\Var{\&b[i]} \in \Fields(\Roots)$ und $\Var{a}$ wird in einer Iteration der \FOREACH-Schleife (Zeile~8f) nach \Var{target} kopiert sowie \Var{b[i]} angepasst.
	
	Ist $\Var{b} \notin \Roots$, so sei \Var{b} ohne Einschränkung aus dem Halbraum \Var{target}.\footnote{Andernfalls ist \Var{b} selbst ein erreichbares Objekt im Halbraum \Var{source} und die Behauptung folgt per Induktion.}
	Da \Var{b} also nach \Var{target} kopiert wurde, wurde \Var{\&b} auch zuvor zur Menge \Var{toDo} hinzugefügt (Zeile~21).
	Foglich kam es zu einer Iteration der \WHILE-Schleife (Zeile~10) mit $\Var{ref} = \Var{\&b}$ und, da $\Var{\&b[i]} \in \Fields(\Var{b})$, wurde auch hier \Var{a} nach \Var{target} kopiert und \Var{b[i]} angepasst.
	Somit werden alle erreichbaren Objekte nach \Var{target} kopiert.	
\end{proof}

Die Laufzeit der kopierenden Garbage Collection ist vergleichbar mit der Markierungsphase des Mark-Sweep-Algorithmus (siehe Satz~\ref{satz:mark-sweep-complexity}), da alle erreichbaren Objekte und ihre Felder aufgesucht bzw. aktualisiert werden müssen.
Hinzu kommen allerdings Verzögerungen, die durch das Kopieren aller erreichbaren Objekte entstehen.
Dies bietet jedoch die Möglichkeit, Objekte innerhalb des Heaps neu anzuordnen:
Abbildung~\ref{fig:fenichel-example} lässt bereits erkennen, dass zwei Objekte, die vom selben Objekt referenziert werden, nebeneinander kopiert werden können.
Das kann sich positiv auf die räumliche Lokalität von zueinander in Beziehung stehenden Objekten auswirken.
Wie bereits in Abschnitt~\ref{sec:mark-sweep-variations} angedeutet, hängt die Ausprägung dieses Effekts stark von der Traversierungsreihenfolge der Objekte -- und damit von der Realisierung der Menge \Var{toDo} -- ab, die optimalerweise an den konkreten Anwendungsfall angepasst wird (vgl. \cite[Kap. 4.2]{handbook}).
Darüber hinaus bietet die Analogie zur Drei-Farben-Abstraktion auch hier die Möglichkeit, die Atomizität des Algorithmus aufzuweichen, indem Objekte, deren ausgehende Referenzen während der Kollektion manipuliert werden, durch geeignete Lese- und Schreibbarrieren gegebenenfalls erneut zu \Var{toDo} hinzugefügt werden (vgl. \cite[S. 129]{kero2007}, \cite[S. 41]{hosking2006}).

Größter und offensichtlicher Nachteil des Algorithmus ist die permanente Halbierung des potenziell verfügbaren Heapspeichers, da ein Halbraum ausschließlich während eines Kollektionszyklus verwendet wird.
Dies erhöht potenziell die Häufigkeit von Garbage-Collection-Zyklen.
Hinzu kommt während der Arbeit des Kollektors zusätzlicher Speicherbedarf zur Verwaltung von \Var{toDo} (siehe Abschnitt~\ref{sec:mark-sweep-variations}) und \Var{newAdr}.
Letzterer lässt jedoch vermeiden, indem etwa die neue Speicheradresse des kopierten Objekts an der ursprünglichen Position hinterlegt wird.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
 % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 


\section{Optimierung von Referenzanpassungen}
\label{sec:handle}
In allen drei vorgestellten Algorithmen war zu sehen, dass eine Anpassung von Referenzen notwendig ist, wenn ein Objekt im Speicher verschoben oder kopiert wird.
Dies erfordert im Allgemeinen eine Anpassung aller Felder von Objekten, die die ursprüngliche Speicheradresse enthalten.
Um den Aufwand hierfür zu reduzieren, können \textbf{Handles} verwendet werden.
Ein Handle \handle{a} eines Objekts \Var{a} ist ein weiteres Objekt, das lediglich die Speicheradresse von \Var{a} enthält und eine feste Position im Speicher besitzt.
Alle Objekte besitzen anstelle einer Referenz auf \Var{a} dann eine solche auf \handle{a}.
Ändert sich die Position von \Var{a} im Speicher, ist ausschließlich eine Anpassung der Speicheradresse in \handle{a} nötig (vgl. \cite{brooks1984}).

\begin{figure}[h]
	\centering
	\includestandalone[scale=0.8]{img/tikz/ch4-handle}~\hspace{1cm}~
	\includestandalone[scale=0.8]{img/tikz/ch4-handle2}
	\caption[Handle zur indirekten Adressierung von Objekten]{Der Handle \handle{a} enthält die Speicheradresse des Objekts \Var{a}. Erfolgt der Zugriff auf \Var{a} ausschließlich über \handle{a}, so genügt es, lediglich die Adresse in \handle{a} anzupassen.}
	\label{fig:handle}
\end{figure}

Die Realisierung dieses Mechanismus kann auf unterschiedlichen Wegen erfolgen.
Denkbar ist unter anderem eine zentrale Tabelle, in der zu jedem Objekt die aktuelle Position aufgeführt wird, die mittels einer eindeutigen ID des Objekts ermittelt werden kann.
Anstelle von Adressen wird vom Mutator dann die ID zur Referenzierung von Objekten verwendet.
Wie bereits in Abschnitt~\ref{sec:rc-optimizing} angedeutet, kann sich das Nachschlagen in großen Tabellen jedoch negativ auf die Performance auswirken.
Alternativ empfehlen \textsc{Kalibera} und \textsc{Jones}, Handles analog zu Objekten zu verwalten und im Heap abzulegen.
Da Handles eine unveränderliche Position besitzen, bietet es sich etwa an, bestimmte Bereiche des Heaps ausschließlich für Handles zu reservieren, die von Kompaktierungsmechanismen ausgespart werden (vgl. \cite[S. 90f]{kalibera2011}).

\begin{algorithm}
\begin{algorithmic}[1]
	\State \MethodHead{new}():
	\State \quad \Var{adr} $\gets$ \Method{allocate}()	
	\State \quad \IF \Var{adr} $=$ \Null
	\State \quad \quad \Method{collect}()
	\State \quad \quad \Var{adr} $\gets$ \Method{allocate}()
	\State \quad \Var{handle} $\gets$ \Method{allocateHandle}()	\Comment{Anforderung im separaten Heapbereich}
	\State \quad \IF \Var{handle} $=$ \Null
	\State \quad \quad \Method{collect}()
	\State \quad \quad \Var{handle} $\gets$ \Method{allocateHandle}()	
	\State \quad \IF \Var{adr} $=$ \Null $\vee$ \Var{handle} $=$ \Null
	\State \quad \quad \Method{error}(\Var{"Nicht genügend Speicher"})
	\State \quad \Var{forward}(\Var{*handle}) $\gets$ \Var{adr}		\Comment{Objektadresse im Handle eintragen}
	\State \quad \Var{handle}(\Var{*adr}) $\gets$ \Var{handle}		\Comment{Handle-Adresse im Objekt eintragen}
	\State \quad \Return \Var{handle}	\Comment{Adresse des Handles zurückgeben}
\end{algorithmic}
\caption[Erzeugung von Objekt und Handle mittels \Method{new}]{Erzeugung von Objekt und Handle mittels \Method{new}. Anstelle einer Referenz auf das eigentliche Objekt erhält der Mutator eine Referenz auf den Handle des Objekts.}
\label{algo:new-handle}
\end{algorithm}

Die in Algorithmus~\ref{algo:new-handle} modifizierte Variante von \Method{new} zur Erzeugung neuer Objekte legt für jedes erzeugte Objekt \Var{a} gleichzeitig einen Handle \handle{a} an, dessen Adresse zurückgegeben wird.
In \Var{forward}(\handle{a}) wird die Adresse von \Var{a} gespeichert, während \Var{handle}(a) eine Referenz auf \handle{a} im Header von \Var{a} bereithält.
Diese ist notwendig, damit nach Verschiebung von \Var{a} der zugehörige Handle gefunden und angepasst werden kann.

Aus Sicht des Mutators soll die Existenz der Handles im Verborgenen bleiben:
Müsste die Entwicklerin auf den korrekten Umgang mit Handles achten, stünde dies im Widerspruch zur Idee einer Garbage Collection, die Entwicklerin von der Speicherverwaltung zu entlasten.
Insofern sollte der Zugriff auf \Var{header}(\Var{a}) nur dem Kollektor ermöglicht werden.
Je nach Programmiersprache müssen dafür auch gewisse Operatoren angepasst werden, wenn sie durch den Mutator verwendet werden.
So muss etwa die Dereferenzierung einer Speicheradresse nicht den Handle, sondern das vom Handle referenzierte Objekt liefern (siehe Algorithmus~\ref{algo:operator-overload}).
Dies kann beispielsweise in der Programmiersprache \Cpp durch Überladung des Adress- und Dereferenzierungsoperators realisiert werden (vgl. \cite[Kap. 18]{cpp}).

\begin{algorithm}
\begin{algorithmic}[1]
	\State \MethodHead{mutatorOperator*}(\Var{ref}):
	\State \quad \Return \Var{*forward}(\Var{*ref})		\Comment{Dereferenziere Speicheradresse im Handle}
	\Statex
	\State \MethodHead{mutatorOperator\&}(\Var{obj}):
	\State \quad \Return \Var{handle}(\Var{obj})		\Comment{Gib Adresse des Handles zurück}
\end{algorithmic}
\caption[Operatoranpassung zur Verbergung von Handles]{Sollen Handles für den Mutator verborgen bleiben, müssen Operatoren überschrieben werden, die mit Speicheradressen von Objekten arbeiten.}
\label{algo:operator-overload}
\end{algorithm}

Die Verwendung von Handles vereinfacht die betrachteten Mark-Compact-Algorithmen deutlich, da auf eine kostspielige Aktualisierung aller Objektfelder verzichtet und eine Anpassung des Handles unmittelbar nach Verschiebung eines Objekts vorgenommen werden kann.
Im LISP-2-Algorithmus wird damit die Prozedur \Method{updateRefs} obsolet und die Buchführung über alte und neue Adressen ist nicht länger notwendig (siehe Algorithmus~\ref{algo:handle-compaction}).
Allerdings besitzen diese Vorteile auch hier ihren Preis:
Da jedes Objekt im Heap einen Handle besitzt, der ebenfalls dynamisch erzeugt wurde, verdoppelt dieser Ansatz die Zahl der Objekte und reduziert den verfügbaren Heapspeicher.
Wie bereits diskutiert kann dies zu häufigeren Garbage-Collection-Zyklen führen, weswegen Handles in Kombination mit der kopierenden Garbage Collection eher unattraktiv sind.
Zudem müssen Handles durch eine eigene Garbage Collection behandelt werden, da sie nicht verschoben werden dürfen.
Zwar ist ein Handle genau dann erreichbar, wenn das zugehörige Objekt erreichbar ist.
Allerdings werden in den oben betrachteten Algorithmen verwaiste Objekte nicht explizit freigegeben, sondern durch andere Objekte überschrieben bzw. dadurch überschreibbar, dass sie sich außerhalb des kompaktierten Bereichs befinden.
Ein gleichzeitiges Freigeben von Handle und Objekt ist somit nicht realisierbar.
Weiter verursacht die feste Position der Handles eine Fragmentierung des Heaps, die eigentlich beseitigt werden soll.
Das Problem lässt sich jedoch in Grenzen halten:
Falls Handles ausschließlich eine einzige Speicheradresse enthalten, belegen sie gegebenenfalls gleich viel Speicher.
Neu erzeugte Handles fügen sich somit passgenau in entstandene Lücken ein.
Nicht zuletzt sollte auch beachtet werden, dass sich Handles auf die Performance des Mutators auswirken können.
Wird auf eine Folge $\Var{a}_1 \rightarrow \Var{a}_2 \rightarrow \dots \rightarrow \Var{a}_n$ von Referenzen von Objekten zugegriffen, so erfolgt zwischen zwei Objekten stets ein Zugriff auf die jeweiligen Handles.
Da Handles und Objekte in verschiedenen Bereichen des Heaps aufbewahrt werden, lässt sich hier keine räumliche Lokalität herstellen, die von Caching-Mechanismen ausgenutzt werden könnte.

\begin{algorithm}
\begin{algorithmic}[1]
	\State \MethodHead{compact}():	\Comment{LISP-2-Algorithmus}
	\State \quad $\Var{pos} \gets \Var{HEAP\_START}$
	\State \quad $\Var{next} \gets \Method{nextMarkedObject}(\Var{HEAP\_START})$
	\State \quad \WHILE $\Var{next} \neq \Null$			
	\State \quad \quad \IF $\Var{pos} \neq \Var{next}$
	\State \quad \quad \quad \Var{forward}(\Var{*handle}(\Var{*next})) $\gets$ \Var{pos}	\Comment{Adresse im Handle anpassen}
	\State \quad \quad \quad \Method{moveObject}(\Var{next}, \Var{pos})
	\State \quad \quad $\Var{pos} \gets \Var{pos} + \Method{sizeOf}(\Var{*pos})$
	\State \quad \quad $\Var{next} \gets \Method{nextMarkedObject}(\Var{next})$
	\Statex
	\State \MethodHead{compactAndUpdate}():		\Comment{Compressor-Algorithmus}
	\State \quad $\Var{pos} \gets \Method{nextMarkedObject}(\Var{HEAP\_START})$
	\State \quad \WHILE $\Var{pos} \neq \Null$
	\State \quad \quad \Var{forward}(\Var{*handle}(\Var{*pos})) $\gets$ \Method{newAddress}(\Var{pos})	\Comment{Handle anpassen}
	\State \quad \quad \Method{moveObject}(\Var{pos}, \Method{newAddress}(\Var{pos}))
	\State \quad \quad $\Var{pos} \gets \Method{nextMarkedObject}(\Var{pos})$
\end{algorithmic}
\caption[Optimierung der Kompaktierungsalgorithmen mit Handles]{Optimierung des LISP-2- und Compressor-Algorithmus mit Handles.}
\label{algo:handle-compaction}
\end{algorithm}